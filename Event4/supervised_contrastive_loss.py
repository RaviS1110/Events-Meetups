# -*- coding: utf-8 -*-
"""supervised_contrastive_loss.ipynb

Automatically generated by Colaboratory.

Original file is located at
    https://colab.research.google.com/drive/169Bey9cCNHNl7flcdhvcAGxtDykZQO_L
"""

from google.colab import drive
drive.mount('/content/drive')

cd "/content/drive/My Drive/supervised_contrastive_loss"

# Commented out IPython magic to ensure Python compatibility.
import matplotlib.pyplot as plt
# %matplotlib inline
import seaborn as sns
import time
import tensorflow as tf
import numpy as np
from tqdm import tqdm_notebook,tqdm
import pandas as pd
from glob import glob
import os
import cv2
from tensorflow.keras.preprocessing.image import *
from tensorflow.keras.optimizers import Adam, SGD
from tensorflow.keras.callbacks import *
from tensorflow.keras import backend as K
from tensorflow.keras.models import *
from tensorflow.keras.layers import *
from tensorflow.keras.utils import Sequence 
from tensorflow.keras import datasets
from sklearn.utils import shuffle
from sklearn.model_selection import StratifiedKFold
import albumentations as albu
from sklearn.metrics import confusion_matrix as cm
import pickle
from shutil import move,copy
from sklearn.decomposition import PCA
from sklearn.manifold import TSNE
import tensorflow_addons as tfa

(train_images, train_labels), (test_images, test_labels) = datasets.cifar10.load_data()

train_images, test_images = train_images / 255.0, test_images / 255.0

train_labels_cat = tf.keras.utils.to_categorical(train_labels)
test_labels_cat = tf.keras.utils.to_categorical(test_labels)

np.random.seed(42)
class_names = ['airplane', 'automobile', 'bird', 'cat', 'deer','dog', 'frog', 'horse', 'ship', 'truck']

plt.figure(figsize=(6,6))
for i in range(9):
    plt.subplot(3,3,i+1)
    plt.xticks([])
    plt.yticks([])
    plt.grid(False)
    plt.imshow(train_images[i], cmap=plt.cm.binary)
    plt.xlabel(class_names[np.where(train_labels_cat[i]==1)[0][0]])
plt.show()

ce_model.compile(loss='categorical_crossentropy',optimizer='adam',metrics=['categorical_accuracy'])

def create_model() :
    
    model = Sequential()
    model.add(Conv2D(32, (3, 3), activation='relu', input_shape=(32, 32, 3)))
    model.add(MaxPooling2D((2, 2)))
    model.add(Conv2D(64, (3, 3), activation='relu'))
    model.add(MaxPooling2D((2, 2)))
    model.add(Conv2D(128, (3, 3), activation='relu'))

    #model.add(Flatten())
    model.add(GlobalAveragePooling2D())
    #model.add(Dense(512, activation='relu'))
    model.add(Dense(64, activation='relu'))
    model.add(Dense(10, activation='softmax'))

    return model

m = create_model()
print(m.summary())

m.compile(optimizer='adam',
          loss = 'categorical_crossentropy',
          metrics=['categorical_accuracy'])

history = m.fit(train_images, train_labels_cat, epochs=5, 
                    validation_data=(test_images, test_labels_cat))

test_loss, test_acc = m.evaluate(test_images,  test_labels_cat, verbose=2)
m.save("ce_loss_cifar10.h5")

def plot_embeddings(emb,labels):
  tl=TSNE()
  embedding=tl.fit_transform(emb)
  fig = plt.figure(figsize = (10, 10))
  sns.scatterplot(embedding[:,0], embedding[:,1], hue=labels)
  plt.show()
  plt.clf()

num_samples = 1280
ce_vector=np.zeros(shape=(num_samples,64))
ce_label_vector=np.zeros(shape=(num_samples,1))

bs = 64
c=0
#p = ce_model.predict(test_images[0:64])

for i in range(20) :
    
    ce_vector[c:c+bs,:] = ce_model.predict(test_images[c:c+bs])
    ce_label_vector[c:c+bs]=test_labels[c:c+bs]

    c += bs

np.unique(ce_label_vector,return_counts=True)

ce_label_vector = ce_label_vector.reshape(num_samples,)
plot_embeddings(ce_vector,ce_label_vector)

class UnitNormLayer(tf.keras.layers.Layer):
    
    def __init__(self,**kwargs):
        super(UnitNormLayer, self).__init__(**kwargs)

    def call(self, input_tensor):
        norm = tf.norm(input_tensor, axis=1)
        return input_tensor / tf.reshape(norm, [-1, 1])

def pdist_euclidean(A):
    # Euclidean pdist
    # https://stackoverflow.com/questions/37009647/compute-pairwise-distance-in-a-batch-without-replicating-tensor-in-tensorflow
    r = tf.reduce_sum(A*A, 1)

    # turn r into column vector
    r = tf.reshape(r, [-1, 1])
    D = r - 2*tf.matmul(A, tf.transpose(A)) + tf.transpose(r)
    return tf.sqrt(D)


def square_to_vec(D):
    '''Convert a squared form pdist matrix to vector form.
    '''
    n = D.shape[0]
    triu_idx = np.triu_indices(n, k=1)
    d_vec = tf.gather_nd(D, list(zip(triu_idx[0], triu_idx[1])))
    return d_vec


def get_contrast_batch_labels(y):
    '''
    Make contrast labels by taking all the pairwise in y
    y: tensor with shape: (batch_size, )
    returns:   
        tensor with shape: (batch_size * (batch_size-1) // 2, )
    '''
    y_col_vec = tf.reshape(tf.cast(y, tf.float32), [-1, 1])
    D_y = pdist_euclidean(y_col_vec)
    d_y = square_to_vec(D_y)
    y_contrasts = tf.cast(d_y == 0, tf.int32)
    return y_contrasts


def get_contrast_batch_labels_regression(y):
    '''
    Make contrast labels for regression by taking all the pairwise in y
    y: tensor with shape: (batch_size, )
    returns:   
        tensor with shape: (batch_size * (batch_size-1) // 2, )
    '''
    raise NotImplementedError


def max_margin_contrastive_loss(z, y, margin=1.0, metric='euclidean'):
    '''
    Wrapper for the maximum margin contrastive loss (Hadsell et al. 2006)
    `tfa.losses.contrastive_loss`
    Args:
        z: hidden vector of shape [bsz, n_features].
        y: ground truth of shape [bsz].
        metric: one of ('euclidean', 'cosine')
    '''
    # compute pair-wise distance matrix
    if metric == 'euclidean':
        D = pdist_euclidean(z)
    elif metric == 'cosine':
        D = 1 - tf.matmul(z, z, transpose_a=False, transpose_b=True)
    # convert squareform matrix to vector form
    d_vec = square_to_vec(D)
    # make contrastive labels
    y_contrasts = get_contrast_batch_labels(y)
    loss = tfa.losses.contrastive_loss(y_contrasts, d_vec, margin=margin)
    # exploding/varnishing gradients on large batch?
    return tf.reduce_mean(loss)

def encoder_network():
	norm_layer = UnitNormLayer()
	
	inputs = Input((32,32,3))

	X = Conv2D(32, (3, 3), activation='relu')(inputs)
	X = MaxPooling2D((2, 2))(X)
	X = Conv2D(64, (3, 3), activation='relu')(X)
	X = MaxPooling2D((2, 2))(X)
	X = Conv2D(128, (3, 3), activation='relu')(X)

	embeddings = GlobalAveragePooling2D()(X)
	#fc1 = Flatten()(X)
	#embeddings = Dense(256, activation='relu')(fc1)
	norm_embeddings = norm_layer(embeddings)

	encoder_network = Model(inputs, norm_embeddings)

	'''
	X = Flatten()(X)
	encoder = Dense(256, activation='relu')(X)

	norm_encoder = norm_layer(encoder)

	projection = Dense(128, activation='relu')(norm_encoder)
	norm_projection =  norm_layer(projection)

	model = Model(inputs,norm_projection)
	'''
	return encoder_network

	'''
	inputs = Input((32,32,3))
	normalization_layer = UnitNormLayer()

	#encoder = tf.keras.applications.ResNet50(weights=None, include_top=False)
	encoder = Model(model.inputs,model.layers[-4].output)
	encoder.trainable = True

	embeddings = encoder(inputs, training=True)
	embeddings = GlobalAveragePooling2D()(embeddings)
	norm_embeddings = normalization_layer(embeddings)

	encoder_network = Model(inputs, norm_embeddings)

	return encoder_network
	'''
# Projector Network
def projector_network():
	projector = tf.keras.models.Sequential([
		Dense(64, activation="relu"),
		UnitNormLayer()
	])

	return projector

K.clear_session()
optimizer = tf.keras.optimizers.Adam()
encoder_r = encoder_network()
projector_z = projector_network()

@tf.function
def train_step(images, labels):
	with tf.GradientTape() as tape:
		r = encoder_r(images, training=True)
		z = projector_z(r, training=True)
		loss = max_margin_contrastive_loss(z, labels)

	gradients = tape.gradient(loss, 
		encoder_r.trainable_variables + projector_z.trainable_variables)
	optimizer.apply_gradients(zip(gradients, 
		encoder_r.trainable_variables + projector_z.trainable_variables))

	return loss

c=0
bs =64
train_loss_results = []

l = 0
for epoch in range(10):	
  epoch_loss_avg = tf.keras.metrics.Mean()
  
  n= np.ceil(len(train_images)/bs).astype('int')
  for step in range(n):
      images,labels=train_images[c:c+bs],train_labels[c:c+bs]

      loss = train_step(images, labels)
    
      epoch_loss_avg.update_state(loss) 

      c += bs
  c=0  
 
  train_loss_results.append(epoch_loss_avg.result())
  if epoch % 1 == 0:
    print("."*30)
    print("Epoch: {} Loss: {:.3f}".format(epoch, epoch_loss_avg.result()))
    print("."*30)

with plt.xkcd():
    plt.plot(train_loss_results)
    plt.title("Supervised Contrastive Loss")
    plt.show()

num_samples=1280

encoded_vector=np.zeros(shape=(num_samples,128))
projected_vector=np.zeros(shape=(num_samples,64))
label_vector=np.zeros(shape=(num_samples,1))

c=0
bs = 64

for step in range(20):
    
    encoded_vector[c:c+bs,:] = encoder_r.predict(test_images[c:c+bs])
    projected_vector[c:c+bs,:] = projector_z.predict(encoded_vector[c:c+bs,:])

    label_vector[c:c+bs]=test_labels[c:c+bs]

    c+=bs

np.unique(label_vector,return_counts=True)

label_vector = label_vector.reshape(num_samples,)
plot_embeddings(projected_vector,label_vector)

def supervised_contrastive_net(encoder,projector,num_classes,act):
  encoder.trainable=False
  projector.trainable=False
  inputs=encoder.input
  x=encoder.layers[-1].output
  x=projector(x)
  x=Dense(num_classes,act, name = 'd1')(x)
  return Model(inputs,x)

K.clear_session()
classifier=supervised_contrastive_net(encoder_r,projector_z,num_classes=10,act='softmax')
cls_optimizer = tf.keras.optimizers.Adam()
classifier.summary()

classifier.compile(loss='categorical_crossentropy',optimizer=cls_optimizer,metrics=['categorical_accuracy'])

classifier.fit(train_images, train_labels_cat, epochs=10,
               validation_data=(test_images, test_labels_cat))

encoder_r.save('encoder_cifar10.h5')
projector_z.save('projector_cifar10.h5')
classifier.save('supervised_contrastive_cifar10.h5')

